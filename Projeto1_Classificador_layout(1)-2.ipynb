{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Carolina Hirschheimer\n",
    "\n",
    "Nome: Rafael Evangelista Monteiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aten√ß√£o:** Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo KitKat.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'KitKat.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'N√£o encontrei o arquivo {filename} aqui no diret√≥rio {os.getcwd()}, ser√° que voc√™ n√£o baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@sabeauanyz pra sempre e depois, √© voc√™ ü§ç</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>acho que os fabricantes do kitkat colocam coca...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>rt @jackwrlght: no twitter voc√™ n√£o tem f√£s, v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>comi meu √∫ltimo kitkat ontem agora t√¥ morrendo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>um a√≠ da civil q n cumprimenta e chega falando...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relev√¢ncia\n",
       "0          @sabeauanyz pra sempre e depois, √© voc√™ ü§ç           0\n",
       "1  acho que os fabricantes do kitkat colocam coca...           2\n",
       "2  rt @jackwrlght: no twitter voc√™ n√£o tem f√£s, v...           0\n",
       "3  comi meu √∫ltimo kitkat ontem agora t√¥ morrendo...           2\n",
       "4  um a√≠ da civil q n cumprimenta e chega falando...           1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>rt @jichuwaifu: comprei 2 kitkat\\ncomi um e t√¥...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@kitkatbrasil bom dia kitkat!!! quando chega e...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>mordi um kitkat de morango pela priemtia vez e...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>meu tio de sp que vai mandar um bolo de kitkat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@animalaleatory @larinha_af  eu tirando teu ki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>@tsoonade n√£o, eu concordo que kitkat e snicke...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>@negohneyy joguei o kitkat por cima como se fo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>@barbosa_crf7 t√¥ passando mal, t√¥ passando mal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>rt @taekook03179038: ningu√©m sabia se a jisoo ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>esqueci o meu kitkat na casa do pitty agora el...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relev√¢ncia\n",
       "0    rt @jichuwaifu: comprei 2 kitkat\\ncomi um e t√¥...           2\n",
       "1    @kitkatbrasil bom dia kitkat!!! quando chega e...           2\n",
       "2    mordi um kitkat de morango pela priemtia vez e...           2\n",
       "3    meu tio de sp que vai mandar um bolo de kitkat...           2\n",
       "4    @animalaleatory @larinha_af  eu tirando teu ki...           1\n",
       "..                                                 ...         ...\n",
       "495  @tsoonade n√£o, eu concordo que kitkat e snicke...           2\n",
       "496  @negohneyy joguei o kitkat por cima como se fo...           2\n",
       "497  @barbosa_crf7 t√¥ passando mal, t√¥ passando mal...           0\n",
       "498  rt @taekook03179038: ningu√©m sabia se a jisoo ...           0\n",
       "499  esqueci o meu kitkat na casa do pitty agora el...           1\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "O produto escolhido √© o chocolate da marca KitKat. Foram considerados <b>irrelevantes</b> (0) todos os tweets que n√£o referiam-se de forma alguma ao produto. J√° os tweets <b>neutros</b> (1) correspodiam √†queles que referiam-se ao KitKat, por√©m n√£o apontavam nenhuma opini√£o relevante em rela√ß√£o ao produto. Por fim, os tweets que n√£o apenas referiam-se ao KitKat, mas tamb√©m apresentavam opini√µes sobre ele foram classificados como <b>relevantes</b> (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Relev√¢ncia'] = train['Relev√¢ncia'].astype('category')\n",
    "test['Relev√¢ncia'] = test['Relev√¢ncia'].astype('category')\n",
    "\n",
    "train['Relev√¢ncia'].cat.categories = ['Irrelevante','Neutro','Relevante']\n",
    "test['Relev√¢ncia'].cat.categories = ['Irrelevante','Neutro','Relevante']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Teste</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relev√¢ncia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>hoje o vasco joga amorrr üí¢üí¢üí¢‚ô•Ô∏è\\n\\n- e eu t√¥ co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Neutro</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>‚Äúposte uma foto da sua mesa de trabalho agora‚Äù...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Relevante</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>pensando no dia que vou ser recebida com kitka...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Teste                                                            \\\n",
       "            count unique                                                top   \n",
       "Relev√¢ncia                                                                    \n",
       "Irrelevante   238    238  hoje o vasco joga amorrr üí¢üí¢üí¢‚ô•Ô∏è\\n\\n- e eu t√¥ co...   \n",
       "Neutro         91     91  ‚Äúposte uma foto da sua mesa de trabalho agora‚Äù...   \n",
       "Relevante     171    171  pensando no dia que vou ser recebida com kitka...   \n",
       "\n",
       "                  \n",
       "            freq  \n",
       "Relev√¢ncia        \n",
       "Irrelevante    1  \n",
       "Neutro         1  \n",
       "Relevante      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby(by=\"Relev√¢ncia\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Treinamento</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relev√¢ncia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>372</td>\n",
       "      <td>372</td>\n",
       "      <td>@jeni_kitkat meu sonho ‚ù§Ô∏è‚ù§Ô∏è</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Neutro</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>eu no supermercado a√≠ o meu era s√≥ 2 kitkat e ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Relevante</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>ando a desejar um mcflury de kitkat h√° 3 dias</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Treinamento         \\\n",
       "                  count unique   \n",
       "Relev√¢ncia                       \n",
       "Irrelevante         372    372   \n",
       "Neutro              135    135   \n",
       "Relevante           243    243   \n",
       "\n",
       "                                                                     \n",
       "                                                           top freq  \n",
       "Relev√¢ncia                                                           \n",
       "Irrelevante                        @jeni_kitkat meu sonho ‚ù§Ô∏è‚ù§Ô∏è    1  \n",
       "Neutro       eu no supermercado a√≠ o meu era s√≥ 2 kitkat e ...    1  \n",
       "Relevante        ando a desejar um mcflury de kitkat h√° 3 dias    1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(by=\"Relev√¢ncia\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIVIS√ÉO DO DATAFRAME POR RELEV√ÇNCIA\n",
    "\n",
    "filtra_relevantes = train[\"Relev√¢ncia\"]==\"Relevante\"\n",
    "filtra_neutros = train[\"Relev√¢ncia\"]==\"Neutro\"\n",
    "filtra_irrelevantes = train[\"Relev√¢ncia\"]==\"Irrelevante\"\n",
    "\n",
    "relevante = train.loc[filtra_relevantes,:]\n",
    "neutro = train.loc[filtra_neutros,:]\n",
    "irrelevante = train.loc[filtra_irrelevantes,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIMPEZA DOS TWEETS \n",
    "\n",
    "import re\n",
    "import emoji\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "def cleanup(text):\n",
    "    punctuation = '[\"\\n\"!-.:?;()''\"\",]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "        \n",
    "# Cria√ß√£o da s√©rie limpa de tweets de treinamento\n",
    "\n",
    "treinamento_string = \"\"\n",
    "for i in train.Treinamento:\n",
    "    treinamento_string+=\" \"+i+\" \"\n",
    "treinamento_string_limpa = cleanup(treinamento_string.lower())\n",
    "split_emoji = emoji.get_emoji_regexp().split(treinamento_string_limpa)\n",
    "split_whitespace = [substr.split() for substr in split_emoji]\n",
    "todas_palavras_treinamento = functools.reduce(operator.concat, split_whitespace)\n",
    "serie_treinamento = pd.Series(todas_palavras_treinamento)\n",
    "\n",
    "# Cria√ß√£o da s√©rie limpa de tweets relevantes\n",
    "\n",
    "relevante_string = \"\"\n",
    "for i in relevante.Treinamento:\n",
    "    relevante_string+=\" \"+i+\" \"\n",
    "relevante_string_limpa = cleanup(relevante_string.lower())\n",
    "split_emoji = emoji.get_emoji_regexp().split(relevante_string_limpa)\n",
    "split_whitespace = [substr.split() for substr in split_emoji]\n",
    "todas_palavras_relevante = functools.reduce(operator.concat, split_whitespace)\n",
    "serie_relevante = pd.Series(todas_palavras_relevante)\n",
    "\n",
    "# Cria√ß√£o da s√©rie limpa de tweets neutros  \n",
    "\n",
    "neutro_string = \"\"\n",
    "for i in neutro.Treinamento:\n",
    "    neutro_string+=\" \"+i+\" \"\n",
    "neutro_string_limpa = cleanup(neutro_string.lower())\n",
    "split_emoji = emoji.get_emoji_regexp().split(neutro_string_limpa)\n",
    "split_whitespace = [substr.split() for substr in split_emoji]\n",
    "todas_palavras_neutro = functools.reduce(operator.concat, split_whitespace)\n",
    "serie_neutro = pd.Series(todas_palavras_neutro)\n",
    "\n",
    "# Cria√ß√£o da s√©rie limpa de tweets irrelevantes\n",
    "\n",
    "irrelevante_string = \"\"\n",
    "for i in irrelevante.Treinamento:\n",
    "    irrelevante_string+=\" \"+i+\" \"\n",
    "irrelevante_string_limpa = cleanup(irrelevante_string.lower())\n",
    "split_emoji = emoji.get_emoji_regexp().split(irrelevante_string_limpa)\n",
    "split_whitespace = [substr.split() for substr in split_emoji]\n",
    "todas_palavras_irrelevante = functools.reduce(operator.concat, split_whitespace)\n",
    "serie_irrelevante = pd.Series(todas_palavras_irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRIA√á√ÉO DAS TABELAS DE FREQU√äNCIA ABSOLUTA:\n",
    "    \n",
    "tabela_treinamento_absoluta = serie_treinamento.value_counts() # S√©rie de treinamento\n",
    "    \n",
    "tabela_relevante_absoluta = serie_relevante.value_counts() # S√©rie de tweets relevantes\n",
    "\n",
    "tabela_neutro_absoluta = serie_neutro.value_counts() # S√©rie de tweets neutros\n",
    "\n",
    "tabela_irrelevante_absoluta = serie_irrelevante.value_counts() # S√©rie de tweets irrelevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o teorema de Naive-Bayes no caso em quest√£o, obt√©m-se:\n",
    "\n",
    "$P(Relevante|tweet) = \\frac{P(tweet|Relevante)P(Relevante)}{P(tweet)}$\n",
    "\n",
    "$P(Neutro|tweet) = \\frac{P(tweet|Neutro)P(Neutro)}{P(tweet)}$\n",
    "\n",
    "$P(Irrelevante|tweet) = \\frac{P(tweet|Irrelevante)P(Irrelevante)}{P(tweet)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "      <th>Relev√¢ncia por Naive Bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>rt @jichuwaifu: comprei 2 kitkat\\ncomi um e t√¥...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@kitkatbrasil bom dia kitkat!!! quando chega e...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>mordi um kitkat de morango pela priemtia vez e...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>meu tio de sp que vai mandar um bolo de kitkat...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@animalaleatory @larinha_af  eu tirando teu ki...</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>amizade n√© https://t.co/wn9xrqsy1b</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>@h3y_catra eu n√£o ri disso n√£o n√©</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>rt @luddiany: n√£o gosta da any? n√£o me siga!\\n...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>rt @deliciasmonique: novidade!! copo de browni...</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>a minha m√£e antes de eu pisar em stm: vai gast...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste   Relev√¢ncia  \\\n",
       "0  rt @jichuwaifu: comprei 2 kitkat\\ncomi um e t√¥...    Relevante   \n",
       "1  @kitkatbrasil bom dia kitkat!!! quando chega e...    Relevante   \n",
       "2  mordi um kitkat de morango pela priemtia vez e...    Relevante   \n",
       "3  meu tio de sp que vai mandar um bolo de kitkat...    Relevante   \n",
       "4  @animalaleatory @larinha_af  eu tirando teu ki...       Neutro   \n",
       "5                 amizade n√© https://t.co/wn9xrqsy1b  Irrelevante   \n",
       "6                  @h3y_catra eu n√£o ri disso n√£o n√©  Irrelevante   \n",
       "7  rt @luddiany: n√£o gosta da any? n√£o me siga!\\n...  Irrelevante   \n",
       "8  rt @deliciasmonique: novidade!! copo de browni...       Neutro   \n",
       "9  a minha m√£e antes de eu pisar em stm: vai gast...  Irrelevante   \n",
       "\n",
       "  Relev√¢ncia por Naive Bayes  \n",
       "0                     Neutro  \n",
       "1                Irrelevante  \n",
       "2                  Relevante  \n",
       "3                  Relevante  \n",
       "4                  Relevante  \n",
       "5                Irrelevante  \n",
       "6                Irrelevante  \n",
       "7                Irrelevante  \n",
       "8                Irrelevante  \n",
       "9                Irrelevante  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C√°lculo das probabilidades totais\n",
    "P_relevante = tabela_relevante_absoluta.sum() / tabela_treinamento_absoluta.sum()\n",
    "P_neutro = tabela_neutro_absoluta.sum() / tabela_treinamento_absoluta.sum()\n",
    "P_irrelevante = tabela_irrelevante_absoluta.sum() / tabela_treinamento_absoluta.sum()\n",
    "\n",
    "# Inicializando vari√°veis para o smoothing:\n",
    "a = 1\n",
    "v = 100000\n",
    "\n",
    "# Cria√ß√£o de lista onde ser√° posteriormente guardada a classifica√ß√£o de cada tweet\n",
    "classificacao = []\n",
    "\n",
    "# Implementa√ß√£o do Naive-Bayes:\n",
    "\n",
    "for tweet in test.Teste:\n",
    "    \n",
    "    # Limpa cada tweet na s√©rie Teste\n",
    "    tweet_limpo = cleanup(tweet.lower())\n",
    "    split_emoji = emoji.get_emoji_regexp().split(tweet)\n",
    "    split_whitespace = [substr.split() for substr in split_emoji]\n",
    "    palavras_tweet = functools.reduce(operator.concat, split_whitespace)\n",
    "    \n",
    "    # Calcula probabilidade do tweet ser relevante\n",
    "    P_tweet_dado_relevante = 1 \n",
    "    for palavra in palavras_tweet:\n",
    "        if palavra in tabela_relevante_absoluta:\n",
    "            P_palavra_dado_relevante = (tabela_relevante_absoluta[palavra] + a) / (tabela_relevante_absoluta.sum() + a*v)\n",
    "        else:\n",
    "            P_palavra_dado_relevante = (a) / (tabela_relevante_absoluta.sum() + a*v)\n",
    "        P_tweet_dado_relevante *= P_palavra_dado_relevante\n",
    "    \n",
    "    # Calcula probabilidade do tweet ser neutro\n",
    "    P_tweet_dado_neutro = 1 \n",
    "    for palavra in palavras_tweet:\n",
    "        if palavra in tabela_neutro_absoluta:\n",
    "            P_palavra_dado_neutro = (tabela_neutro_absoluta[palavra] + a) / (tabela_neutro_absoluta.sum() + a*v)\n",
    "        else:\n",
    "            P_palavra_dado_neutro = (a) / (tabela_neutro_absoluta.sum() + a*v)\n",
    "        P_tweet_dado_neutro *= P_palavra_dado_neutro\n",
    "    \n",
    "    # Calcula probabilidade do tweet ser irrelevante\n",
    "    P_tweet_dado_irrelevante = 1 \n",
    "    for palavra in palavras_tweet:\n",
    "        if palavra in tabela_irrelevante_absoluta:\n",
    "            P_palavra_dado_irrelevante = (tabela_irrelevante_absoluta[palavra] + a) / (tabela_irrelevante_absoluta.sum() + a*v)\n",
    "        else:\n",
    "            P_palavra_dado_irrelevante = (a) / (tabela_irrelevante_absoluta.sum() + a*v)\n",
    "        P_tweet_dado_irrelevante *= P_palavra_dado_irrelevante\n",
    "        \n",
    "    # Compara√ß√£o das probabilidades por Naive-Bayes \n",
    "    # e classifica√ß√£o em uma nova coluna \"Rele√¢ncia por Naive-Bayes, na s√©rie Teste\"\n",
    "    P_relevante_dado_tweet_vezes_P_tweet = P_tweet_dado_relevante*P_relevante\n",
    "    P_neutro_dado_tweet_vezes_P_tweet = P_tweet_dado_neutro*P_neutro\n",
    "    P_irrelevante_dado_tweet_vezes_P_tweet = P_tweet_dado_irrelevante*P_irrelevante\n",
    "    \n",
    "    if P_relevante_dado_tweet_vezes_P_tweet>P_neutro_dado_tweet_vezes_P_tweet and P_relevante_dado_tweet_vezes_P_tweet>P_irrelevante_dado_tweet_vezes_P_tweet:\n",
    "        classificacao.append(\"Relevante\")\n",
    "    \n",
    "    if P_neutro_dado_tweet_vezes_P_tweet>P_relevante_dado_tweet_vezes_P_tweet and P_neutro_dado_tweet_vezes_P_tweet>P_irrelevante_dado_tweet_vezes_P_tweet:\n",
    "        classificacao.append(\"Neutro\")\n",
    "        \n",
    "    if P_irrelevante_dado_tweet_vezes_P_tweet>P_relevante_dado_tweet_vezes_P_tweet and P_irrelevante_dado_tweet_vezes_P_tweet>P_neutro_dado_tweet_vezes_P_tweet:\n",
    "        classificacao.append(\"Irrelevante\")\n",
    "        \n",
    "test['Relev√¢ncia por Naive Bayes'] = classificacao\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Relev√¢ncia por Naive Bayes</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Neutro</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relev√¢ncia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Neutro</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Relevante</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Relev√¢ncia por Naive Bayes  Irrelevante  Neutro  Relevante\n",
       "Relev√¢ncia                                                \n",
       "Irrelevante                       0.416   0.002      0.058\n",
       "Neutro                            0.066   0.006      0.110\n",
       "Relevante                         0.050   0.008      0.284"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela = pd.crosstab(test[\"Relev√¢ncia\"],test[\"Relev√¢ncia por Naive Bayes\"],normalize=\"all\")\n",
    "tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de verdadeiros positivos:  28.4 %\n",
      "Probabilidade de falsos positivos:  16.8 %\n",
      "Probabilidade de verdadeiros negativos:  41.6 %\n",
      "Probabilidade de falsos negativos:  11.6 %\n"
     ]
    }
   ],
   "source": [
    "P_verdadeiros_positivos = tabela.iloc[2,2]\n",
    "P_falsos_positivos = tabela.iloc[1,2] + tabela.iloc[0,2]\n",
    "P_verdadeiros_negativos = tabela.iloc[0,0]\n",
    "P_falsos_negativos = tabela.iloc[1,0] + tabela.iloc[2,0]\n",
    "\n",
    "print(\"Probabilidade de verdadeiros positivos: \",(P_verdadeiros_positivos*100).round(2),\"%\")\n",
    "print(\"Probabilidade de falsos positivos: \",(P_falsos_positivos*100).round(2),\"%\")\n",
    "print(\"Probabilidade de verdadeiros negativos: \",(P_verdadeiros_negativos*100).round(2),\"%\")\n",
    "print(\"Probabilidade de falsos negativos: \",(P_falsos_negativos*100).round(2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do classificador Naive-Bayes, entre os tweets da s√©rie de teste, <b>28,4%</b> foram classificados corretamente como relevantes, enquanto <b>16,8%</b> foram classificados incorretamente como relevantes, ao passo em que <b>41,6%</b> foram classificados corretamente como irrelevantes e <b>11,6%</b> foram classificados incorretamente como irrelevantes.\n",
    "\n",
    "Tendo isso em vista, pode-se considerar que o classificador constru√≠do <b>n√£o possui uma excelente performance</b>. Devido √† maior quantidade de dados irrelevantes, relevantes e neutros, respectivamente, pode-se considerar que o classificador teve uma melhor performance, quanto maior o n√∫mero de tweets analisados. Com isso, explica-se que a taxa de verdadeiros negativos √© maior que a de verdadeiros positivos. \n",
    "\n",
    "Nesse sentido, √© interessante observar como os tweets envolvendo <b>sarcasmo</b> e <b>dupla nega√ß√£o</b> foram interpretados. Como exemplo de dupla nega√ß√£o, pode-se analisar o tweet <i>\"@h3y_catra eu n√£o ri disso n√£o n√©\"</i> que foi corretamente classificado pelo Naive Bayes como irrelevante. Al√©m disso, o tweet de dupla nega√ß√£o <i>\"odeio kitkat v√©i bagui muito caro pro tamanho dele e nem √© t√£o bom assim!\"</i> tamb√©m foi classificado corretamente, no caso, como relevante. Enquanto isso, para verificar como tweets com sarcasmo s√£o interpretados, √© poss√≠vel analisar a classifica√ß√£o do seguinte tweet: <i>\"@yaaxbb fala n√£o! comi um kitkat s√≥ pra aumentar a vontade!\"</i>, que foi classificado corretamente como relevante. Dessa forma, conclui-se que os tweets de dupla nega√ß√£o e sarcasmo n√£o geraram grandes impactos de falsos positivos ou negativos. \n",
    "\n",
    "Finalmente, gostaria de enfatizar que o classificador, apesar de ainda estar suscet√≠vel a melhorias, pode ainda ser expandido para an√°lise de uma s√©rie de outros fatores com rela√ß√£o √† marca. Se fosse alvo de um <b>plano de expans√£o</b>, al√©m de dividir os tweets conforme rel√¢ncia, o classificador poderia segment√°-los em tweets que falam sobre o KitKat positivamente ou negativamente, bem como os tweets que tem rela√ß√£o com algum produto espec√≠fico, por exemplo o lan√ßamento de um novo sabor de KitKat e a avalia√ß√£o da sua recep√ß√£o por parte dos consumidores. Portanto, √© de grande interesse da pr√≥pria empresa <b>continuar financiando</b> o projeto em quest√£o, j√° que ele tem potencial para fornecer diversos dados que podem direcionar medidas da companhia com rela√ß√£o a campanhas de marketing, cria√ß√£o de novos sabores, entre diversos outros aspectos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u> Outras reflex√µes relevantes:  </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Por que n√£o √© poss√≠vel alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets?\n",
    "\n",
    "N√£o √© poss√≠vel alimentar a base de treinamento usando o classificador, uma vez que o objetivo do dataframe de treinamento √© justamente ter uma base de dados que com certeza est√° categorizada corretamente, para que essa base de dados seja utilizada para \"ensinar\" o classificador quais palavras d√£o ind√≠cios de que o tweet √© mais ou menos relevante. Nesse sentido, √© crucial que a classifica√ß√£o na s√©rie de treinamento seja feita pelo homem, para que o classificador Naive-Bayes \"aprenda\" de uma base de dados correta. Caso a alimenta√ß√£o fosse realizada pelo classificador, haveria uma margem de tweets classificados incorretamente como relevantes, ou irrelevantes, de modo que isso aumentaria a taxa de erro do classificador, que j√° aprenderia de uma base de dados que possui falsos positivos e negativos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Outros cen√°rios de uso para o classificador Naive-Bayes:\n",
    "\n",
    "O classificador Naive Bayes pode ser utilizado em uma s√©rie de outros cen√°rios, al√©m do aqui apresentado. Entre eles, pode-se identificar:\n",
    "\n",
    "* classifica√ß√£o de emails da caixa de entrada de um usu√°rio como poss√≠vel spam ou n√£o-spam;\n",
    "* an√°lise das transa√ß√µes de um cart√£o de cr√©dito e classifica√ß√£o de poss√≠vel fraude;\n",
    "* classifica√ß√£o de pacientes de acordo com a probabilidade de terem determinado diagn√≥stico dado o laudo de exames;\n",
    "* classifica√ß√£o de poss√≠veis posts que um usu√°rio gostaria de ver no feed, dados os posts que ele curte atualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Melhorias reais no classificador com indica√ß√µes concretas de como implementar (n√£o √© preciso codificar, mas indicar como fazer. Indique material de pesquisa sobre o assunto).\n",
    "\n",
    "A fim de melhorar a efic√°cia do classificador Naive Bayes, seria poss√≠vel realizar as seguintes melhorias no c√≥digo:\n",
    "\n",
    "* <b>Calcular as probabilidades em log.</b> Como as probabilidades s√£o n√∫meros entre 0 e 1, ao multiplicar as probabilidades, obt√©m-se um n√∫mero muito pequeno. Por isso, √© poss√≠vel haver dificuldades com a precis√£o dos pontos, como em casos de under-runs. Para evitar esse problema, √© poss√≠vel trabalhar com o logaritmo das probabilidades, de modo a aumentar os valores comparados.\n",
    "\n",
    "* <b>Classifica√ß√£o dos tweets em duas categorias por vez.</b> Ao inv√©s de utilizar diversas categorias, tipicamente, o m√©todo \"uma em oposi√ß√£o √†s demais\" costuma ser mais eficaz para o Naive Bayes. Em outras palavras, uma poss√≠vel melhoria seria classificar primeiro em uma classe \"A\" e outra \"todo resto\", depois classe \"B\" e \"todo resto\" e assim por diante. \n",
    "\n",
    "* <b>Pr√©-processamento e an√°lise dos dados.</b> Al√©m da limpeza de pontua√ß√£o, espe√ßos, entre outros elementos, √© poss√≠vel realizar outros m√©todos de pr√©-processamento dos dados que podem auxiliar na efic√°cia do classificador Naive Bayes. A seguir, apresento alguns deles:\n",
    "\n",
    "    <b>a)</b> Usar uma bilbioteca de stemming, como Porter, Lancaster e Snowball, para somar a contabiliza√ß√£o de palavras com a mesma raiz. No c√≥digo aqui demonstrado, por exemplo, as palavras \"gostamos\", \"gostaria\", \"gostava\" s√£o contabilizadas singularmente. Utilizando essa ferramenta, poderia ser contabilizado a soma de suas freequ√™ncias absolutas, como todas as palavras com raiz \"gostar\".\n",
    "    \n",
    "    <b>b)</b> Encontrar sin√¥nimos. Da mesma forma que o stemming, gostar, apreciar, curtir, poderiam ser contabilizados como um √∫nico termo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
